2025-02-08 09:14:03,888 - INFO - Dataset columns: ['conversations']
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:03<00:00, 2904.65 examples/s]
Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2898/2898 [00:00<00:00, 3061.11 examples/s]
  0%|                                                                                                                                                                     | 1/7500 [00:24<51:26:47, 24.70s/it]Traceback (most recent call last):
  File "/root/fine_tuning_Llama/scripts/train.py", line 362, in <module>
    main()
  File "/root/fine_tuning_Llama/scripts/train.py", line 337, in main
    perplexity = train_and_evaluate(
                 ^^^^^^^^^^^^^^^^^^^
  File "/root/fine_tuning_Llama/scripts/train.py", line 200, in train_and_evaluate
    optimizer.step()
  File "/opt/conda/lib/python3.11/site-packages/accelerate/optimizer.py", line 165, in step
    self.scaler.step(self.optimizer, closure)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/sharded_grad_scaler.py", line 294, in step
    return super().step(optimizer, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py", line 410, in step
    self.unscale_(optimizer)
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/sharded_grad_scaler.py", line 262, in unscale_
    optimizer_state["found_inf_per_device"] = self._unscale_grads_(
                                              ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/sharded_grad_scaler.py", line 221, in _unscale_grads_
    self._foreach_non_finite_check_and_unscale_cpu_(
  File "/opt/conda/lib/python3.11/site-packages/torch/distributed/fsdp/sharded_grad_scaler.py", line 169, in _foreach_non_finite_check_and_unscale_cpu_
    torch.isinf(grad).any().item() is True
    ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
